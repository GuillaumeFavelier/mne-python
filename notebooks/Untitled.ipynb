{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ipyvolume 3d backend.\n",
      "\n",
      "Reading /home/guillaume/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 55 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 61 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 67 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 58 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "[<Evoked  |  'Left Auditory' (mean, N=55), [-0.1998, 0.49949] sec, 376 ch, ~4.8 MB>, <Evoked  |  'Right Auditory' (mean, N=61), [-0.1998, 0.49949] sec, 376 ch, ~4.8 MB>, <Evoked  |  'Left visual' (mean, N=67), [-0.1998, 0.49949] sec, 376 ch, ~4.8 MB>, <Evoked  |  'Right visual' (mean, N=58), [-0.1998, 0.49949] sec, 376 ch, ~4.8 MB>]\n",
      "Using surface from /home/guillaume/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem.fif.\n",
      "Getting helmet for system 306m\n",
      "Prepare EEG mapping...\n",
      "Computing dot products for 59 electrodes...\n",
      "Computing dot products for 2562 surface locations...\n",
      "Field mapping data ready\n",
      "    Preparing the mapping matrix...\n",
      "    Truncating at 21/59 components to omit less than 0.001 (0.00097)\n",
      "    The map will have average electrode reference\n",
      "Prepare MEG mapping...\n",
      "Computing dot products for 305 coils...\n",
      "Computing dot products for 304 surface locations...\n",
      "Field mapping data ready\n",
      "    Preparing the mapping matrix...\n",
      "    Truncating at 210/305 components to omit less than 0.0001 (9.9e-05)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5e1c59c8f145198d2f93baea136fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(animation=0.0, camera=PerspectiveCamera(fov=46.0, position=(0.08682408883346518, 0.86602â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mne.viz import set_3d_backend\n",
    "set_3d_backend(\"ipyvolume\")\n",
    "\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "data_path = mne.datasets.sample.data_path()\n",
    "fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis-ave.fif')\n",
    "evoked = mne.read_evokeds(fname, baseline=(None, 0), proj=True)\n",
    "print(evoked)\n",
    "evoked_l_aud = evoked[0]\n",
    "evoked_r_aud = evoked[1]\n",
    "evoked_l_vis = evoked[2]\n",
    "evoked_r_vis = evoked[3]\n",
    "subjects_dir = data_path + '/subjects'\n",
    "trans_fname = data_path + '/MEG/sample/sample_audvis_raw-trans.fif'\n",
    "\n",
    "maps = mne.make_field_map(evoked_l_aud, trans=trans_fname, subject='sample',\n",
    "                          subjects_dir=subjects_dir, n_jobs=1)\n",
    "\n",
    "# Finally, explore several points in time\n",
    "field_map = evoked_l_aud.plot_field(maps, time=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ipysurfer)",
   "language": "python",
   "name": "ipysurfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
